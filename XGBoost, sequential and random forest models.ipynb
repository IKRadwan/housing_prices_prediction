{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #obliczenia numeryczne\n",
    "import pandas as pd #struktura dataframe\n",
    "import matplotlib.pyplot as plt #do rysowania wykresow, macierz korelacji\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('dataset/train.csv', index_col='Id')\n",
    "\n",
    "test_df = pd.read_csv('dataset/test.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6917f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tworze kopie i zmienne dla X_prep i y_prep, aby skorzystac z Mutual information przed wyborem modelu i wlasciwym trenowaniem\n",
    "#aby uniknac nadpisania danych, na ktroych docelowo bede pracowac\n",
    "\n",
    "X_prep = train_df.copy()\n",
    "y_prep = X_prep.pop('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyswietlam info ile jest brakujacych danych dla danej kolumny\n",
    "\n",
    "\n",
    "print(test_df.isnull().sum().sort_values(ascending=False).head(40))\n",
    "\n",
    "#wszystkich danych (domow) jest 1460\n",
    "#PoolQC - Pool Quality (kat) - NA(1453) znaczy No Pool, wiec nie sa to brakujace dane\n",
    "#MiscFeature - rozne cechy nie ujete w innych kategoriach (kat) - np. winda; NA oznacza brak takich cech, wiec cos nam to mowi\n",
    "#Alley: Type of alley access to property; NA - brak dostepu do alei dojazdowej\n",
    "#Fence - NA - brak ogrodzenia\n",
    "#FireplaceQu - Fireplace quality; NA - no fireplace\n",
    "#LotFrontage (LICZBOWE) - Stopy liniowe ulicy połączonej z nieruchomością; NA to brak ulicy? raczej brak danych -> most frequent\n",
    "#GARAGE - wszystkie brakujace dane w year building dotycza braku garazu; \n",
    "#BsmtFinType2 - ocena powierzchni wykonczonej piwnicy; NA - brak piwnicy\n",
    "#BsmtExposure - ekspozycja piwnicy (NA - brak piwnicy)\n",
    "#BsmtCond i te 2 ponizej - NA - brak piwnicy; \n",
    "#MasVnrArea i Type- none - brak forniru murowanego + jego powierzchnia (liczbowy) - tutaj brakuje danych, bo na brak forniru jest\n",
    "#none a nie n/a; dobrze wypelnic najczesciej wystepujacymi wartosciami\n",
    "#Electrical - dana jakosciowa; najlepiej wypelnic najczesciej wystepujaca \n",
    "\n",
    "#jakosciowe kolumny, ktore trzeba uzupelnic o najczesciej wystepujace wartosci:\n",
    "#1. MasVnrType \n",
    "#2. Electrical\n",
    "\n",
    "#ilosciowe, ktore trzeba uzupelnic o najczesciej wystepujace wartosci:\n",
    "#1. LotFrontage\n",
    "#2. GarageYrBlt\n",
    "#3. MasVnrArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_prep.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9703e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#korzystam z Mutual information zeby sprawdzic, ktore atrybuty najsilniej wplywaja na y\n",
    "\n",
    "\n",
    "# koduje atykiety dla wartości kategorycznych\n",
    "for colname in X_prep.select_dtypes(\"object\"):\n",
    "    X_prep[colname], _ = X_prep[colname].factorize()\n",
    "\n",
    "# sprawdzam czy w X_prep sa same wartości całkowite (musza byc zeby skorzystac z MI)\n",
    "discrete_features = X_prep.dtypes == int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976df3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_prep.isnull().sum().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80009637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pozbywam sie brakujacych danych poprzez imputacje - wypelniam brakujace wartosci najczesciej wystepujaca w danej kolumnie\n",
    "#powinno byc dla jakosciowych i ilosciowych na raz\n",
    "\n",
    "# Imputation\n",
    "my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_X_prep = pd.DataFrame(my_imputer.fit_transform(X_prep))\n",
    "\n",
    "# Imputacja usuwa nazwy kolumn, dlatego je przywracam\n",
    "imputed_X_prep.columns = X_prep.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "all(discrete_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6163af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for colname in imputed_X_prep.select_dtypes('float64'):\n",
    "    print(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep = imputed_X_prep.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e2a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b390844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mi_scores(X, y, discrete_features):\n",
    "    mi_scores = mutual_info_regression(X_prep, y_prep, discrete_features=discrete_features)\n",
    "    mi_scores = pd.Series(mi_scores, index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "mi_scores = compute_mi_scores(X_prep, y_prep, discrete_features)\n",
    "mi_scores.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "\n",
    "\n",
    "plt.figure(dpi=100, figsize=(8, 20))\n",
    "plot_mi_scores(mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6752a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep['SalePrice'] = y_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2717ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwam kolumny z niskim MI (później będę sprawdzać, czy usunięcie danej kolumny dobrze wpływało na wynik modelu)\n",
    "col_to_delete = ['PoolQC', 'MoSold', 'PoolArea', 'BsmtFinSF2', 'LowQualFinSF', 'Exterior1st', 'Utilities']\n",
    "\n",
    "for col in col_to_delete:\n",
    "    train_df.drop(col, axis = 1, inplace= True)\n",
    "    test_df.drop(col, axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyswietlam info ile jest brakujacych danych dla danej kolumny dla danych treningowych\n",
    "\n",
    "\n",
    "print(train_df.isnull().sum().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747777e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyswietlam info ile jest brakujacych danych dla danej kolumny dla danych testowych\n",
    "\n",
    "\n",
    "print(test_df.isnull().sum().sort_values(ascending=False).head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c92b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df.SalePrice\n",
    "train_full = train_df.drop(['SalePrice'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W kolumnie GarageYearBlt wszystkie brakujące wartości są związane z brakiem garażu (nie ma garażu – nie ma roku budowy garażu). \n",
    "# Ponieważ nie mogę uzupełnić tych brakujących wartości wartościami ‚0’, wybiorę modę. Nie jest to jednak idealnie rozwiązanie, \n",
    "# dlatego przygotuje dla modelu dodatkową kolumnę z informacją tylko o istnieniu garażu, aby podkreślić, że brak garażu występuje \n",
    "# tylko przy wartościach most_frequent dla kolumny GarageYearBlt\n",
    "\n",
    "\n",
    "train_full['GarageBlt'] = train_full['GarageYrBlt'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c172ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['GarageBlt'] = test_df['GarageYrBlt'] > 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d39fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation\n",
    "cols_miss_val = ['MasVnrType', 'MSZoning', 'LotFrontage', 'GarageYrBlt', 'MasVnrArea', 'BsmtFullBath', 'BsmtHalfBath', \n",
    "                 'Exterior2nd', 'KitchenQual', 'SaleType', 'GarageArea', 'GarageCars', 'BsmtUnfSF', 'BsmtFinSF1',\n",
    "                'TotalBsmtSF']\n",
    "\n",
    "my_imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputed_train_full = pd.DataFrame(my_imputer.fit_transform(train_full[cols_miss_val]))\n",
    "imputed_test_df = pd.DataFrame(my_imputer.transform(test_df[cols_miss_val]))\n",
    "\n",
    "# Imputation removed column names; put them back\n",
    "imputed_train_full.columns = cols_miss_val\n",
    "imputed_test_df.columns = cols_miss_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = train_full.drop(cols_miss_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop(cols_miss_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full.reset_index(drop=True, inplace=True)\n",
    "imputed_train_full.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "imputed_test_df.reset_index(drop=True, inplace=True)\n",
    "train_df_concat = pd.concat([train_full, imputed_train_full], axis=1)\n",
    "test_df_concat = pd.concat([test_df, imputed_test_df], axis=1)\n",
    "train_df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_concat.LotFrontage = train_df_concat.LotFrontage.astype('float64')\n",
    "train_df_concat.GarageYrBlt = train_df_concat.GarageYrBlt.astype('float64')\n",
    "train_df_concat.MasVnrArea = train_df_concat.MasVnrArea.astype('float64')\n",
    "train_df_concat.BsmtFullBath = train_df_concat.BsmtFullBath.astype('float64')\n",
    "train_df_concat.BsmtHalfBath = train_df_concat.BsmtHalfBath.astype('float64')\n",
    "\n",
    "test_df_concat.LotFrontage = test_df_concat.LotFrontage.astype('float64')\n",
    "test_df_concat.GarageYrBlt = test_df_concat.GarageYrBlt.astype('float64')\n",
    "test_df_concat.MasVnrArea = test_df_concat.MasVnrArea.astype('float64')\n",
    "test_df_concat.BsmtFullBath = test_df_concat.BsmtFullBath.astype('float64')\n",
    "test_df_concat.BsmtHalfBath = test_df_concat.BsmtHalfBath.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "categorical_cols = [cname for cname in train_df_concat.columns if train_df_concat[cname].nunique() < 10 and \n",
    "                        train_df_concat[cname].dtype == \"object\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9158f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in train_df_concat.columns if train_df_concat[cname].dtype in ['int64', 'float64']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad5e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeda374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_df_concat[categorical_cols]))\n",
    "OH_cols_test = pd.DataFrame(OH_encoder.transform(test_df_concat[categorical_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_df_concat.index\n",
    "OH_cols_test.index = test_df_concat.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_df_concat[numerical_cols]#train_df_concat.drop(categorical_cols, axis=1)\n",
    "num_X_test = test_df_concat[numerical_cols]#test_df_concat.drop(categorical_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e50f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29094724",
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f564e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(OH_X_train, y, train_size=0.8, test_size=0.2, random_state=1)\n",
    "\n",
    "#ODTAD DANE PRZYGOTOWANE DO DALSZYCH MODELI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e65c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055db87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(n_estimators=2000, learning_rate = 0.01, n_jobs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b950d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "model.fit(X_train, y_train,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = model.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean Absolute Error: \" + str(mean_absolute_error(preds, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd4251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(model, OH_X_train, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f98c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#przygotowujemy plik do submitu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_test = OH_X_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292edbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('dataset/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_testing = test_df.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fill in the line below: get test predictions\n",
    "preds_test = model.predict(final_X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': cols_for_testing,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('dataset/XGBoost_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbb5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#koniec xgboost, teraz sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c1e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fd8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HousePrices():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation = 'relu', kernel_regularizer = regularizers.l2(0.001), input_shape=(237,)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(64, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(32, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(16, activation = 'relu', kernel_regularizer = regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(1, activation = 'linear'))\n",
    "    model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34a70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sequential = HousePrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X_train).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56148b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(y_train).reshape(1168,1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b2f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_sequential.fit(np.array(X_train), np.array(y_train), epochs = 45, batch_size = 64, validation_split =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1631ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_valid = model_sequential.predict(np.array(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e662939",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = mean_absolute_error(y_valid, preds_valid)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d46eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model_sequential.predict(np.array(final_X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test.reshape(1459).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd7393",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "\n",
    "output = pd.DataFrame({'Id': cols_for_testing,\n",
    "                       'SalePrice': preds_test.reshape(1459)})\n",
    "output.to_csv('dataset/sequential_model_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest dodaje z plikyu random_forest (z gita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adb4398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69064570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    \"\"\"Return the average MAE over 5 CV folds of random forest model.\n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    \"\"\" \n",
    "    my_pipeline = Pipeline(steps=[\n",
    "        ('model', RandomForestRegressor(n_estimators=n_estimators, random_state=1))\n",
    "    ])\n",
    "        \n",
    "    score = -1 * cross_val_score(my_pipeline, OH_X_train, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    return score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {} \n",
    "keys = [50, 200, 350, 500, 650, 800, 950, 1100, 1250, 1400]\n",
    "for key in keys:\n",
    "    results[key] = get_score(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.ylabel(\"error\")\n",
    "plt.xlabel(\"n_estimators (number of trees)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae747d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(n_estimators=1300, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(steps=[('model', model_rf)\n",
    "                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1e8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the line below: get test predictions\n",
    "preds_test = my_pipeline.predict(final_X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': cols_for_testing,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('dataset/random_forest_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bfdc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
